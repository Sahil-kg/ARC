{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 67357,
          "databundleVersionId": 8951125,
          "sourceType": "competition"
        },
        {
          "sourceId": 76250,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 64069,
          "modelId": 88118
        }
      ],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "ARC Resolver. LSTM Only",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sahil-kg/ARC/blob/main/ARC_Resolver_LSTM_Only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n"
      ],
      "metadata": {
        "id": "lBRSeDZHJ-xs"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "arc_prize_2024_path = kagglehub.competition_download('arc-prize-2024')\n",
        "arwani_arc_puzzle_solver_v1_pytorch_v1_1_path = kagglehub.model_download('arwani/arc-puzzle-solver-v1/PyTorch/v1/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "FPPBFNe4J-xu"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Try hard\n",
        "\n",
        "Author: Arwani Maulana / aronei44 / shiroe\n",
        "\n",
        "### Note\n",
        "\n",
        "this notebook almost generate perfect output but the competition using accuracy so the score must be 0.\n",
        "\n",
        "if you like this notebook please upvote.... hehe"
      ],
      "metadata": {
        "id": "GzvSFuXYJ-xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Import Necessary Modules')\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm # taqadum for loading ui\n",
        "import json # for read json\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, datasets\n",
        "from collections import Counter"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T03:49:32.56699Z",
          "iopub.execute_input": "2024-07-20T03:49:32.567778Z",
          "iopub.status.idle": "2024-07-20T03:49:38.829091Z",
          "shell.execute_reply.started": "2024-07-20T03:49:32.567747Z",
          "shell.execute_reply": "2024-07-20T03:49:38.828325Z"
        },
        "trusted": true,
        "id": "DU3flrnlJ-xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BASE_FOLDER = '/kaggle/input/arc-prize-2024'\n",
        "CMAP = colors.ListedColormap(\n",
        "    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
        "     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
        "NORM = colors.Normalize(vmin=0, vmax=10)\n",
        "BATCH_SIZE = 128\n",
        "file_paths = {\n",
        "    \"train_file_path\": {\n",
        "        \"data_file_path\": f\"{BASE_FOLDER}/arc-agi_training_challenges.json\",\n",
        "        \"target_file_path\": f\"{BASE_FOLDER}/arc-agi_training_solutions.json\"\n",
        "    },\n",
        "    \"val_file_path\": {\n",
        "        \"data_file_path\": f\"{BASE_FOLDER}/arc-agi_evaluation_challenges.json\",\n",
        "        \"target_file_path\": f\"{BASE_FOLDER}/arc-agi_evaluation_solutions.json\"\n",
        "    },\n",
        "    \"test_file_path\": {\n",
        "        \"data_file_path\": f\"{BASE_FOLDER}/arc-agi_test_challenges.json\"\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T03:49:38.830544Z",
          "iopub.execute_input": "2024-07-20T03:49:38.830983Z",
          "iopub.status.idle": "2024-07-20T03:49:38.889504Z",
          "shell.execute_reply.started": "2024-07-20T03:49:38.830954Z",
          "shell.execute_reply": "2024-07-20T03:49:38.888511Z"
        },
        "trusted": true,
        "id": "wlFMNUDvJ-xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ARC Dataset Class\n",
        "\n",
        "Data has different sizes/shapes for both input and output. this class produces the same form. 2703 for input and 900 for output;"
      ],
      "metadata": {
        "id": "tp7CM6UKJ-xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ARC Dataset Class\")\n",
        "class ARCDataset:\n",
        "\n",
        "    def __init__(self, train_file_path, val_file_path, test_file_path, batch_size):\n",
        "        self.output = {\n",
        "            \"train_output\":{},\n",
        "            \"val_output\":{}\n",
        "        }\n",
        "        self.origin_data = {}\n",
        "        self.train_data = self.extract_file(train_file_path, \"train\")\n",
        "        self.val_data = self.extract_file(val_file_path, \"val\")\n",
        "        self.test_data = self.extract_file(test_file_path, \"test\")\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    #   for dataset class, we just need the input and output data\n",
        "    def extract_data(self, data):\n",
        "        d = []\n",
        "        for key, inps, targ, index in data:\n",
        "            d.append([inps, targ])\n",
        "        return d\n",
        "\n",
        "    def train_dataset(self):\n",
        "        return DataLoader(self.extract_data(self.train_data), batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataset(self):\n",
        "        return DataLoader(self.extract_data(self.val_data), batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataset(self):\n",
        "        return self.test_data\n",
        "\n",
        "    #   extract json file\n",
        "    def extract_file(self, file_path, type_data):\n",
        "        data_file_path = file_path[\"data_file_path\"]\n",
        "        target_file_path = file_path[\"target_file_path\"] if type_data != \"test\" else None\n",
        "        if target_file_path != None:\n",
        "            with open(target_file_path, 'r') as f:\n",
        "                sol = json.load(f)\n",
        "            for i in sol.keys():\n",
        "                self.output[f\"{type_data}_output\"][i] = sol[i]\n",
        "        return self.load_data(data_file_path, type_data)\n",
        "\n",
        "    def load_data(self, file_path, type_data):\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        self.origin_data[type_data] = data\n",
        "        return self.parse_data(data, type_data)\n",
        "\n",
        "    #   add '0' value for padding. each row must have 30 length\n",
        "    def expand_data(self, data, data_append=0):\n",
        "        return np.array([*data, *[data_append for _ in range(30 - len(data))]])\n",
        "\n",
        "    #   add '0' or np.zeros(30) so the data shape become (30,30) (900 after flatten)\n",
        "    def prep_data(self, data):\n",
        "        data = np.array(data)\n",
        "\n",
        "        ndata = []\n",
        "        for d in data:\n",
        "            ndata.append(self.expand_data(d, 0))\n",
        "        return torch.tensor(self.expand_data(ndata, np.zeros(30)).flatten())\n",
        "\n",
        "    # the input data idea is give the nn example_input + example_target + test_input so LSTM can remember what it should do\n",
        "    def parse_data(self, data, type_data):\n",
        "        ndata = []\n",
        "        for key in tqdm(data.keys(), desc=type_data):\n",
        "            train_data = data[key]['train']\n",
        "            test_data = data[key]['test']\n",
        "            train_temp, test_temp = [], []\n",
        "            for trd in train_data:\n",
        "                input_tensor = self.prep_data(trd['input'])\n",
        "                output_tensor = self.prep_data(trd['output'])\n",
        "                train_temp.append([\n",
        "                    input_tensor,\n",
        "                    output_tensor\n",
        "                ])\n",
        "            for i in range(len(test_data)):\n",
        "                input_tensor = self.prep_data(test_data[i]['input'])\n",
        "                if type_data != 'test' and key in self.output[f\"{type_data}_output\"]:\n",
        "                    output_tensor = self.prep_data(self.output[f\"{type_data}_output\"][key][i])\n",
        "                else:\n",
        "                    output_tensor = np.zeros(900)\n",
        "                test_temp.append([\n",
        "                    input_tensor,\n",
        "                    output_tensor\n",
        "                ])\n",
        "            for i, trd_1 in enumerate(train_temp):\n",
        "                for j, tsd in enumerate(test_temp):\n",
        "                    ndata.append([key, torch.tensor([*[*trd_1[0], 10, *trd_1[1]], 11, *tsd[0], 10]), torch.tensor(tsd[1]), j])\n",
        "\n",
        "        print(f\"Data type: {type_data}. Unique Puzzle: {len(data.keys())}. Parsing Puzzle: {len(ndata)}\")\n",
        "        return ndata"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T03:49:38.891109Z",
          "iopub.execute_input": "2024-07-20T03:49:38.891465Z",
          "iopub.status.idle": "2024-07-20T03:49:38.912292Z",
          "shell.execute_reply.started": "2024-07-20T03:49:38.891433Z",
          "shell.execute_reply": "2024-07-20T03:49:38.911338Z"
        },
        "trusted": true,
        "id": "30f7SjwwJ-xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ARCDataset(**file_paths, batch_size=BATCH_SIZE)\n",
        "\n",
        "train_origin = dataset.origin_data[\"train\"]\n",
        "val_origin = dataset.origin_data[\"val\"]\n",
        "test_origin = dataset.origin_data[\"test\"]\n",
        "\n",
        "train_dataset = dataset.train_dataset()\n",
        "val_dataset = dataset.val_dataset()\n",
        "test_dataset = dataset.test_dataset()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T03:49:38.914864Z",
          "iopub.execute_input": "2024-07-20T03:49:38.915178Z",
          "iopub.status.idle": "2024-07-20T03:50:04.348761Z",
          "shell.execute_reply.started": "2024-07-20T03:49:38.915152Z",
          "shell.execute_reply": "2024-07-20T03:50:04.347826Z"
        },
        "trusted": true,
        "id": "0ho1m2PQJ-xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimension Class\n",
        "\n",
        "We must reconstruct the output for the right size. Model generate only 30 x 30 size but the real output size has a different size. Using the original data, this class try to get right output size"
      ],
      "metadata": {
        "id": "z8YnJMHxJ-xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimension Class\")\n",
        "class Dimension:\n",
        "    def __init__(self, data):\n",
        "        self.dim = self.extract_dim(data)\n",
        "\n",
        "    def extract_dim(self, data):\n",
        "        keys = list(data.keys())\n",
        "        ndata = {}\n",
        "        for key in tqdm(keys):\n",
        "            data_row = data[key]\n",
        "            ndata[key] = self.check_dim(data_row)\n",
        "        return ndata\n",
        "\n",
        "    def dim(self, data):\n",
        "        return np.array(data).shape\n",
        "\n",
        "    def get_dim(self, data):\n",
        "        inp_dim = self.dim(data['input'])\n",
        "        out_dim = self.dim(data['output']) if 'output' in data else [1,1]\n",
        "        return inp_dim, out_dim\n",
        "\n",
        "    #   check the habits of data. if the input and output sizes are always same, its easier to get the right output size\n",
        "    def check_dim(self,data):\n",
        "        train_data = data[\"train\"]\n",
        "        test_data = data[\"test\"]\n",
        "        train_dim = []\n",
        "        for d in train_data:\n",
        "            inp_dim, out_dim = self.get_dim(d)\n",
        "            same = inp_dim == out_dim\n",
        "            diff1 = out_dim[0] / inp_dim[0]\n",
        "            diff2 = out_dim[1] / inp_dim[1]\n",
        "            train_dim.append([\n",
        "                *inp_dim,\n",
        "                *out_dim,\n",
        "                int(same),\n",
        "                diff1,\n",
        "                diff2\n",
        "            ])\n",
        "        out_dim_data = []\n",
        "        for i in range(len(test_data)):\n",
        "            inp_dim, out_dim = self.get_dim(test_data[i])\n",
        "            same = all([s[4] for s in train_dim])\n",
        "            if same:\n",
        "                out_dim = inp_dim\n",
        "            else:\n",
        "                for dim in train_dim:\n",
        "                    if inp_dim[0] == dim[0] and inp_dim[1] == dim[1]:\n",
        "                        out_dim = (dim[2], dim[3])\n",
        "                        break\n",
        "                y1 = Counter([dim[5] for dim in train_dim]).most_common(1)[0][0]\n",
        "                y2 = Counter([dim[6] for dim in train_dim]).most_common(1)[0][0]\n",
        "                out_dim = (int(inp_dim[0] * y1), int(inp_dim[1] * y2))\n",
        "            out_dim_data.append(out_dim)\n",
        "        return out_dim_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T03:50:04.350183Z",
          "iopub.execute_input": "2024-07-20T03:50:04.350669Z",
          "iopub.status.idle": "2024-07-20T03:50:04.365379Z",
          "shell.execute_reply.started": "2024-07-20T03:50:04.350612Z",
          "shell.execute_reply": "2024-07-20T03:50:04.364462Z"
        },
        "trusted": true,
        "id": "c2G07k6IJ-xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Class\n",
        "\n",
        "Long-Short Term Memory, a Recurrent Neural Network model that can remember patterns. Usually used for Natural Language Processing. This algorithm imitates the human brain which can remember things in the long or short term."
      ],
      "metadata": {
        "id": "1VjF3oRTJ-x0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('LSTM Class')\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, INPUT_SIZE, OUTPUT_SIZE, HIDDEN_SIZE):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(INPUT_SIZE, HIDDEN_SIZE, batch_first=True)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        lstm_out, _ = self.lstm(input_data)\n",
        "        predictions = self.fc(lstm_out)\n",
        "        return predictions"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T03:50:04.36654Z",
          "iopub.execute_input": "2024-07-20T03:50:04.36682Z",
          "iopub.status.idle": "2024-07-20T03:50:04.377775Z",
          "shell.execute_reply.started": "2024-07-20T03:50:04.366797Z",
          "shell.execute_reply": "2024-07-20T03:50:04.376823Z"
        },
        "trusted": true,
        "id": "1Lks0cQgJ-x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training Class')\n",
        "class Training:\n",
        "    def __init__(self, model, train_loader, criterion, optimizer, device, loss = 100):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.loss = loss\n",
        "\n",
        "    def _train_one(self, model, data, criterion, optimizer):\n",
        "        # declare model for train mode\n",
        "        model.train()\n",
        "\n",
        "        # data is on cpu, transfer to gpu if gpu is available\n",
        "        input_data, target = data\n",
        "        input_data, target = input_data.to(self.device).float(), target.to(self.device).float()\n",
        "\n",
        "        # get the output\n",
        "        output = model(input_data)\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def _train_loop(self, model, train_loader, criterion, optimizer):\n",
        "        model.train()\n",
        "        history = {'train_loss': []}\n",
        "        loss = self.loss\n",
        "        epoch = 0\n",
        "        patient = 0\n",
        "        while True:\n",
        "            epoch += 1\n",
        "            train_loss = 0\n",
        "            for data in train_loader:\n",
        "                ls = self._train_one(model, data, criterion, optimizer)\n",
        "                train_loss += ls\n",
        "            train_loss /= len(train_loader)\n",
        "            history['train_loss'].append(train_loss)\n",
        "\n",
        "            print(f'\\rEpoch : {epoch}, Loss: {train_loss:.5f}, Lowest Loss: {loss:.5f}, Patient: {patient}', end='')\n",
        "\n",
        "            # if loss is smaller than before, save the model\n",
        "            if train_loss < loss:\n",
        "                loss = train_loss\n",
        "                torch.save(model.state_dict(), 'model.pth')\n",
        "                patient = 0\n",
        "            else:\n",
        "                patient += 1\n",
        "            # I'm being greedy here. Sorry. if you dont like it, just remove 'and epoch > 2500'\n",
        "            if patient >= 20 and epoch > 2500:\n",
        "                break\n",
        "\n",
        "        self.loss = loss\n",
        "        return history\n",
        "\n",
        "    def train(self):\n",
        "        history = self._train_loop(self.model, self.train_loader, self.criterion, self.optimizer)\n",
        "        self._plot_loss(history)\n",
        "\n",
        "    def _plot_loss(self, history):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(history['train_loss'], 'o-', label='train_loss')\n",
        "        plt.legend()\n",
        "        plt.title('Loss Plot')\n",
        "        plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T03:50:04.379185Z",
          "iopub.execute_input": "2024-07-20T03:50:04.379539Z",
          "iopub.status.idle": "2024-07-20T03:50:04.393916Z",
          "shell.execute_reply.started": "2024-07-20T03:50:04.379503Z",
          "shell.execute_reply": "2024-07-20T03:50:04.393063Z"
        },
        "trusted": true,
        "id": "KM1zJ9bwJ-x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IN_DIM = len(test_dataset[1][1]) # 2703\n",
        "OUT_DIM = 900\n",
        "LATENT_DIM = 1800"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T03:50:04.394976Z",
          "iopub.execute_input": "2024-07-20T03:50:04.395251Z",
          "iopub.status.idle": "2024-07-20T03:50:04.40485Z",
          "shell.execute_reply.started": "2024-07-20T03:50:04.395222Z",
          "shell.execute_reply": "2024-07-20T03:50:04.40396Z"
        },
        "trusted": true,
        "id": "F9BAi0RYJ-x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training start\n",
        "\n",
        "Just because I've already made a model before, I'm just making a few adjustments here.\n",
        "\n",
        "- Learning Rate (lr) before = 0.001\n",
        "- Learning Rate (lr) now    = 0.0001"
      ],
      "metadata": {
        "id": "yB5bCoEmJ-x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Start training with train data\")\n",
        "model = LSTM(IN_DIM, OUT_DIM, LATENT_DIM).to(DEVICE)\n",
        "criterion = nn.MSELoss()\n",
        "# load pre trained model\n",
        "model.load_state_dict(torch.load('/kaggle/input/arc-puzzle-solver-v1/pytorch/v1/1/model.pth',map_location=DEVICE))\n",
        "# Fine Tuning with smaller learning rate\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "training = Training(model, train_dataset, criterion, optimizer, DEVICE)\n",
        "training.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T03:50:04.405989Z",
          "iopub.execute_input": "2024-07-20T03:50:04.406242Z",
          "iopub.status.idle": "2024-07-20T04:09:09.266556Z",
          "shell.execute_reply.started": "2024-07-20T03:50:04.40622Z",
          "shell.execute_reply": "2024-07-20T04:09:09.265082Z"
        },
        "trusted": true,
        "id": "2lxW7BlRJ-x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the best model from previous training\n",
        "model.load_state_dict(torch.load('model.pth'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T04:09:11.832198Z",
          "iopub.execute_input": "2024-07-20T04:09:11.832565Z",
          "iopub.status.idle": "2024-07-20T04:09:11.956197Z",
          "shell.execute_reply.started": "2024-07-20T04:09:11.832534Z",
          "shell.execute_reply": "2024-07-20T04:09:11.955063Z"
        },
        "trusted": true,
        "id": "x9gm165qJ-x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Prediction Class')\n",
        "class Prediction:\n",
        "    def __init__(self, model, data, origin_data, output = {}):\n",
        "        self.model = model\n",
        "        self.data = data\n",
        "        self.origin_data = origin_data\n",
        "        self.dimension = Dimension(origin_data)\n",
        "        self.parsed_data = {}\n",
        "        self.output = output\n",
        "\n",
        "    def score(self, data, key):\n",
        "        s = []\n",
        "        if key not in self.output:\n",
        "            return 0\n",
        "        for d in range(len(data)):\n",
        "            attempt = []\n",
        "            output = np.array(self.output[key][d])\n",
        "            attempt_1 = np.array(data[d]['attempt_1'])\n",
        "            attempt_2 = np.array(data[d]['attempt_2'])\n",
        "\n",
        "            if output.shape != attempt_1.shape:\n",
        "                attempt.append(0)\n",
        "            else:\n",
        "                attempt.append(int(all(output.flatten() == attempt_1.flatten())))\n",
        "\n",
        "            if output.shape != attempt_2.shape:\n",
        "                attempt.append(0)\n",
        "            else:\n",
        "                attempt.append(int(all(output.flatten() == attempt_2.flatten())))\n",
        "\n",
        "            s.append(max(attempt))\n",
        "        return max(s)\n",
        "\n",
        "    def calculate_score(self):\n",
        "        score, data_count = 0, 0\n",
        "        for key in self.parsed_data.keys():\n",
        "            data = self.parsed_data[key][\"test\"]\n",
        "            score += self.score(data, key)\n",
        "            data_count += 1\n",
        "        print(f\"Total Data: {data_count}. Total Correct: {score}. Accuracy: {score/data_count}\")\n",
        "\n",
        "    def predict(self, model, data):\n",
        "        model.eval()\n",
        "        input_data, target = data\n",
        "        input_data, target = torch.tensor(input_data).to(DEVICE).float(), torch.tensor(target).to(DEVICE).float()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            input_data = input_data.unsqueeze(0)\n",
        "            output = model(input_data)\n",
        "\n",
        "        return output[0]\n",
        "\n",
        "    def extract_dim(self, key, output, idx=0):\n",
        "        origin_data = self.origin_data[key]\n",
        "        dim = self.dimension.dim[key][idx]\n",
        "        data = np.array(output).astype(int).reshape(30,30)\n",
        "        ndata = []\n",
        "        for i in range(dim[0]):\n",
        "            row_data = data[i]\n",
        "            ndata.append(row_data[:dim[1]])\n",
        "        return np.array(ndata)\n",
        "\n",
        "    def get_output(self, attempt_1, attempt_2, model, key, idx=0):\n",
        "        out1 = self.predict(model, attempt_1)\n",
        "        out2 = self.predict(model, attempt_2)\n",
        "        out1 = self.extract_dim(key, torch.round(out1.cpu()), idx).tolist()\n",
        "        out2 = self.extract_dim(key, torch.round(out2.cpu()), idx).tolist()\n",
        "        return out1, out2\n",
        "\n",
        "    def plot_train(self, data):\n",
        "        print(\"Train Data\")\n",
        "        fig, ax = plt.subplots(2, len(data), figsize=(len(data) * 2, 2))\n",
        "        ax = np.array(ax)  # Ensure ax is always a 2D array\n",
        "        for i in range(len(data)):\n",
        "            ax[0, i].imshow(data[i]['input'], cmap=CMAP, norm=NORM)\n",
        "            ax[1, i].imshow(data[i]['output'], cmap=CMAP, norm=NORM)\n",
        "        plt.show()  # Add this to display the plot\n",
        "\n",
        "    def plot_test(self, data):\n",
        "        print(\"Test Data\")\n",
        "        fig, ax = plt.subplots(3, len(data), figsize=(len(data) * 3, 3))\n",
        "        ax = np.array(ax)  # Ensure ax is always a 2D array\n",
        "        if len(data) > 1:\n",
        "            for i in range(len(data)):\n",
        "                ax[0, i].imshow(data[i]['input'], cmap=CMAP, norm=NORM)\n",
        "                ax[1, i].imshow(data[i]['attempt_1'], cmap=CMAP, norm=NORM)\n",
        "                ax[2, i].imshow(data[i]['attempt_2'], cmap=CMAP, norm=NORM)\n",
        "        else:\n",
        "            ax[0].imshow(data[0]['input'], cmap=CMAP, norm=NORM)\n",
        "            ax[1].imshow(data[0]['attempt_1'], cmap=CMAP, norm=NORM)\n",
        "            ax[2].imshow(data[0]['attempt_2'], cmap=CMAP, norm=NORM)\n",
        "        plt.show()  # Add this to display the plot\n",
        "\n",
        "    def pred_all(self):\n",
        "        model = self.model\n",
        "        origin_data = self.origin_data\n",
        "        temp_data = {}\n",
        "        submit_data = {}\n",
        "        for data in tqdm(self.data):\n",
        "\n",
        "            key = data[0]\n",
        "            idx = data[3]\n",
        "            data_input = [data[1], data[2]]\n",
        "\n",
        "            if key not in temp_data:\n",
        "                temp_data[key] = {}\n",
        "            if idx not in temp_data[key]:\n",
        "                temp_data[key][idx] = {\n",
        "                    \"attempt_1\": data_input,\n",
        "                    \"attempt_2\": data_input\n",
        "                }\n",
        "            else:\n",
        "                temp_data[key][idx][\"attempt_2\"] = data_input\n",
        "\n",
        "        for key in tqdm(temp_data.keys()):\n",
        "            data_list = temp_data[key]\n",
        "            data_list = {key: data_list[key] for key in sorted(data_list)}\n",
        "            for data in data_list:\n",
        "                data_row = data_list[data]\n",
        "                at1, at2 = self.get_output(data_row[\"attempt_1\"], data_row[\"attempt_2\"],model,key, data)\n",
        "                origin_data[key][\"test\"][data][\"attempt_1\"] = at1\n",
        "                origin_data[key][\"test\"][data][\"attempt_2\"] = at2\n",
        "\n",
        "        for key in origin_data.keys():\n",
        "            submit_data[key] = origin_data[key][\"test\"]\n",
        "        self.parsed_data = origin_data\n",
        "        return submit_data\n",
        "\n",
        "    def plot_all(self, step=1):\n",
        "        count = 0\n",
        "        parsed_data = self.parsed_data\n",
        "        for key in parsed_data.keys():\n",
        "            count+=1\n",
        "            if count % step != 0:\n",
        "                continue\n",
        "            print(f\"===== {key} =====\")\n",
        "            self.plot_train(parsed_data[key][\"train\"])\n",
        "            self.plot_test(parsed_data[key][\"test\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T04:21:16.748935Z",
          "iopub.execute_input": "2024-07-20T04:21:16.749304Z",
          "iopub.status.idle": "2024-07-20T04:21:16.785504Z",
          "shell.execute_reply.started": "2024-07-20T04:21:16.749265Z",
          "shell.execute_reply": "2024-07-20T04:21:16.784371Z"
        },
        "trusted": true,
        "id": "RXXc_GcfJ-x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sanity = Prediction(model, dataset.train_data, train_origin, dataset.output['train_output'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T04:21:17.184093Z",
          "iopub.execute_input": "2024-07-20T04:21:17.184477Z",
          "iopub.status.idle": "2024-07-20T04:21:17.250846Z",
          "shell.execute_reply.started": "2024-07-20T04:21:17.184428Z",
          "shell.execute_reply": "2024-07-20T04:21:17.249694Z"
        },
        "trusted": true,
        "id": "F8WpYazRJ-x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sanity.pred_all()\n",
        "sanity.calculate_score()\n",
        "# sanity.plot_all(15)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T04:21:17.553387Z",
          "iopub.execute_input": "2024-07-20T04:21:17.554138Z",
          "iopub.status.idle": "2024-07-20T04:21:18.45696Z",
          "shell.execute_reply.started": "2024-07-20T04:21:17.554102Z",
          "shell.execute_reply": "2024-07-20T04:21:18.45607Z"
        },
        "trusted": true,
        "id": "GtelYxANJ-x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = Prediction(model, dataset.test_dataset(), test_origin)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T04:21:38.79551Z",
          "iopub.execute_input": "2024-07-20T04:21:38.796233Z",
          "iopub.status.idle": "2024-07-20T04:21:38.820559Z",
          "shell.execute_reply.started": "2024-07-20T04:21:38.796198Z",
          "shell.execute_reply": "2024-07-20T04:21:38.819692Z"
        },
        "trusted": true,
        "id": "6GYSmaASJ-x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = pred.pred_all()\n",
        "pred.plot_all(15)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T04:21:40.048746Z",
          "iopub.execute_input": "2024-07-20T04:21:40.049383Z",
          "iopub.status.idle": "2024-07-20T04:21:46.66339Z",
          "shell.execute_reply.started": "2024-07-20T04:21:40.049339Z",
          "shell.execute_reply": "2024-07-20T04:21:46.662418Z"
        },
        "trusted": true,
        "id": "qoKaOJNrJ-x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_object = json.dumps(res, indent=4)\n",
        "with open('submission.json', 'w') as f:\n",
        "    f.write(json_object)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-20T04:22:32.098182Z",
          "iopub.execute_input": "2024-07-20T04:22:32.098551Z",
          "iopub.status.idle": "2024-07-20T04:22:32.165757Z",
          "shell.execute_reply.started": "2024-07-20T04:22:32.098521Z",
          "shell.execute_reply": "2024-07-20T04:22:32.164759Z"
        },
        "trusted": true,
        "id": "r5OXrhYNJ-x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5rOc6crtJ-x3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}